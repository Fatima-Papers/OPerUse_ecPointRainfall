Numerical Weather Prediction (NWP) models have been continuously improving over the last years,  although improve continuously in reliability and skill, represent an average over the model grid-box. 

Whilst, for some applications, users require forecasts at specific locations. Despite NWP modelling advancements, significant weather events will still happen at a location within the gaps, in time and space, not picked by the models. Experienced forecasters add value to predictions issued for smaller scales than the model resolution as they understand model biases and model errors at (sub-)grid scale, interpret how they might impact the weather at a specific location, and summarize all this information in an intelligible way for the relevant users. 
However, forecasters call upon past model performance experience, which can take years to build up, might generate biased forecasts based on what such experience can recall, and can take some time to adapt it to new model versions. 

However, forecasters call upon past model performance experience, which can take years to build up, might generate biased forecasts based on what such experience can recall, and can take some time to adapt it to new model versions. 

A new statistical post-processing methodology (ecPoint) can help to overcome these challenges, e.g. the probabilities that ecPoint assigns to a point forecast do not depend on personal experiences, ecPoint provides automatically adapts the probabilities for an event for new model versions, and helps forecasters to mathematically summarize the probabilistic information contained in the raw forecasts. However, ecPoint adds layers of complexity to traditional probabilistic ensemble-based forecasts (PEFs), and it is currently not fully understood whether traditional training provided for standard PEFs is sufficient to train forecasters in the use of ecPoint forecasts and favour its adoption in operational environments. During a one-year trial, the Hungarian Meteorological Service (OMSZ) and the National Meteorological Institute of Costa Rica (IMN) used ecPoint-Rainfall forecasts to predict extreme localized rainfall events. The overall impression is that ecPoint-Rainfall could improve the predictions for such events if tailored training is provided, no matter what is the prior forecasters experience with PEFs.

\textit{"Forecasts possess no intrinsic value. They acquire value through their ability to influence the decisions made by users of the forecasts”} \citep{Murphy1993}. Thus increases in forecast accuracy do not necessarily imply increases in forecast value, as the quality/value relationship is user and problem-specific. \par
Let's examine the diffusion of adoption of probabilistic ensemble-based forecasts (PEFs). \citet{Lorenz1963} advocated that the chaotic nature of the atmosphere would impose a limit on how far ahead deterministic predictions could work. In the 1990s, the emergence of ensemble prediction systems (EPSs) marked de facto the paradigm shift from a deterministic to a probabilistic approach as such systems predict not only the most likely weather scenario but also its probability of occurrence, as well as other possible alternative outcomes \citep{Bauer2015,Buizza2018a,Palmer2019}. Today, providing the uncertainty around a forecast \textit{“is not} [seen anymore as] \textit{a bolt-on extra, but rather a sine qua non”} to deliver a prediction which would otherwise be incomplete \citep{Palmer2017}. EPSs also provide more consistent, less “jumpy” predictions. Without such characteristics, forecasts become more difficult to handle and can cause users to lose confidence in the forecasts \citep{Richardson2020}. \par
Theoretical studies \citep{Richardson2000,Richardson2001,Palmer2002,Zhu2002,Buizza2008} have shown that PEFs do possess more value than deterministic predictions and, later, controlled empirical studies \citep{Roulston2006,Joslyn2007,Roulston2009,Joslyn2010,Joslyn2012,Joslyn2013,Ramos2013,Arnal2016} have supported that claim, showing also that forecasts that acknowledge uncertainty explicitly seem more realistic, trustworthy, and complete. However, even the more sophisticated PEFs have little or no value if they are misunderstood or misused by en end-user and therefore, the way to effectively and accurately communicate a forecast to end-users is critical \citep{Du2007}. Indeed, the aforementioned empirical studies have also found that forecasters and end-users do understand uncertainty information and use it correctly to make better decisions as long as some care is taken in how uncertainty information is presented. However, identifying effective methods of communicating forecast uncertainty has been challenging over the years, and for this reason some meteorological centres still base their forecasts on deterministic models \citep{NationalResearchCouncil2006,AMS2008}. \par
Therefore, even the most recent discussions \citep{Zhang2019}  highlight the importance of giving proper attention to the whole forecasting chain to expand the adoption of PEFs to a broader group of end-users. This includes (i) continuous improvements in the formulation of probabilistic weather predictions, (ii) using post-event analysis to constantly evaluate and update communication strategies for low-probability high-impact events without reducing trust through, (iii) user-engagement, (iv) user-testing, and (v) awareness of design principles. \par
In 2019, a new post-processed point-rainfall product, called ecPoint-Rainfall became operational at ECMWF. A one-year global verification showed that, for points, ecPoint-Rainfall provides more reliable and skilful rainfall forecasts than the raw ECMWF ensemble (ENS), with marked improvements in the discrimination ability for extreme rainfall events (> 50 mm/12h) in the medium range being particularly noteworthy \citep{Hewson2020a}. However, the new product was not assessed from a user perspective. ecPoint-Rainfall adds layers of complexity to standard PEFs and, without a user-focused evaluation, it is impossible to assess to what extent end-users, including those experienced in probabilistic weather forecasting, might find the interpretation of the new forecasts conceptually challenging. Such complexity might lead to a misunderstanding or misuse of the product, eventually undermining a possible broader adoption. Therefore, this study aims to assess whether traditional PEF guidelines are appropriate also for ecPoint-Rainfall, or whether they would need to be somehow tailored to best communicate the specific features and the added value of this new product, even in case of experienced users of probabilistic forecasts. \par
Hungary and Costa Rica have meteorological services with different experience in probabilistic weather forecasting, and they volunteered to test ecPoint-Rainfall within their operational environments over a one-year trial period. Both  meteorological services reported on the ecPoint-Rainfall performance in predicting extreme rainfall events that caused significant impacts in their own countries during the trial. Such analysis complements the more general verification carried out by \citet{Hewson2020a} by illustrating the performance of ecPoint-Rainfall in two different climatological regions of the world. Then, subsequent discussions were carried out to understand how ecPoint-Rainfall was viewed  operationally, and which aspects might condition in future its full adoption within operational environments. \par
Section 2 discusses the experience of Hungary and Costa Rica in probabilistic weather forecasting. Section 3  introduces ecPoint-Rainfall. Section 4 presents the design of products based on ecPoint-Rainfall developed at both meteorological services and how they were subsequently used in a  evaluation of the post-processed rainfall forecasts. Section 5 discusses the outcomes of such subjective evaluation. Concluding remarks are presented in section 5.
According to \citet{Fundel2019}, users need the opportunity to familiarise with the quality of new products in their everyday practice in order to appreciate their entire value in decision-making processes.